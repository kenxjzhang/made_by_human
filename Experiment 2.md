---
tags:
created: 2025-08-28
description: "This document is for Experiment #2, which examines the 'disclosure credibility' and 'source credibility'"
---
2025-09-22 09:36
Main goal of Experiment #2:
1. Replicate the results in Experiment #1
2. Explore the mechanisms to explain the patterns
 
 # Experiment 2 Design - 2025-09-14 10:08

### Mechanism 1
1. Question: When you were reading the report, how would you describe the focus of your attention?

 Response Scale: 7-point scale with detailed anchors

|                                                                                         |     |     |                                                    |     |     |                                                                                                                   |
| --------------------------------------------------------------------------------------- | --- | --- | -------------------------------------------------- | --- | --- | ----------------------------------------------------------------------------------------------------------------- |
| 1                                                                                       | 2   | 3   | 4                                                  | 5   | 6   | 7                                                                                                                 |
| Almost entirely on the content of the report (the facts, arguments, and recommendation) |     |     | An equal focus on both the content and its origins |     |     | Almost entirely on the process used to create the report (who wrote it, how it was prepared, and its credibility) |
### Mechanism 2
How truthful do you believe the disclosure statement was about the actual use of AI in the report?

|                     |     |     |         |     |     |                     |
| ------------------- | --- | --- | ------- | --- | --- | ------------------- |
| 1                   | 2   | 3   | 4       | 5   | 6   | 7                   |
| Not at all truthful |     |     | Neutral |     |     | Completely truthful |
### Mechanism 3

==Analyst:==

Competence:

- I feel confident in this analyst's abilities.

- The analyst has good knowledge about the companies.

- The analyst has the expertise needed to make good investment recommendations.

Benevolence:

- The analyst seems to have my best interests at heart.

- The analyst likely cares about the welfare of investors like me.

- I believe the analyst genuinely wants to help me make a good investment decision.

Integrity:

- The analyst seems honest.

- The analyst appears to have a strong sense of moral principles.

- I believe the analyst would be truthful in their communications.

==Firm==

Competence:

- This firm is highly competent in the investment industry.

- The firm has the resources and expertise to provide high-quality investment advice.

- I am confident in this firm's ability to perform its job well.

Benevolence:

- This firm puts its clients' interests ahead of its own.

- This firm seems to genuinely care about its clients' financial success.

- Helping clients is a top priority at this firm.

Integrity:

- This firm operates with a high degree of integrity.

- The firm adheres to sound ethical principles.

- I believe this firm is honest in its dealings with clients.



### Attitudes towards AI
Please indicate the extent to which you agree or disagree with the following statements about artificial intelligence.
7-point Likert scale (1 = Strongly Disagree, 7 = Strongly Agree)
1. _AI_ has more advantages than disadvantages.
2. I prefer technologies that do not feature _AI._ (R)
3. When I think about _AI_, I have mostly positive feelings.


# General thoughts
Two competing mechanism:
1.  People doubt the credibility of the Generative AI disclosure
	1. Opens the new mechanism on how the doubt would interact with other factors (expertise/trust) 
2. People have no doubt about the credibility -- but they now interpret the No use of AI or Mix use of AI as a negative signal to follow the report; re-evaluation of source credibility
	- Emotional trust towards analyst/firm (peripheral route)
	- Expertise of analyst/firm (central route) 
		- One measure on firm reputation/status
- Potential mechanism of ELM persuasion

We should also find a way to measure the 'Human involvement level' in the report
We should measure people's perception towards AI and Human efficiency in prediction. Simple and straightforward

Rodríguez et al. (2024)
>The ELM states that a persuasive message can affect the amount and direction of an attitude change in three ways: affecting the _argument quality_ (i.e., the persuasiveness of the message itself), affecting the recipient’s _argument elaboration_, and serving as a _peripheral cue_.
>
>While _“argument quality”_ refers to how the message is constructed by the source or persuader, _“argument elaboration”_ refers to the recipient’s cognitive elaboration; the latter affects information processing, especially the motivation to scrutinize a message. One factor influencing argument elaboration is personal relevance, also called involvement ([Cacioppo & Petty, 1982](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr9-00332941241291497); [Petty et al., 1981](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr52-00332941241291497)). When a topic has high personal relevance, the tendency to carefully consider argument quality is greater; however, when personal relevance is low, the message’s peripheral cues become more dominant. Other important factors also influencing argument elaboration are personal responsibility ([Petty & Cacioppo, 1986](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr51-00332941241291497)), self-perceived vulnerability ([Das et al., 2003](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr16-00332941241291497)), thought confidence ([Petty et al., 2002](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr50-00332941241291497); [Briñol et al., 2023](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr77-00332941241291497)), and the need for cognition ([Cacioppo & Petty, 1982](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr9-00332941241291497)), among others. Lastly, _peripheral cues_ act when the elaboration is low or absent. In this case, some of the most common cues the recipient uses are source expertise ([Cacioppo & Petty, 1982](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr9-00332941241291497); [Petty et al., 1981](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr52-00332941241291497)), source attractiveness ([Chaiken, 1979](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr10-00332941241291497)), and emotions ([Petty & Briñol, 2015](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr49-00332941241291497)), among others. Regarding emotions, its relationship with persuasion is complex and has effects via multiple processes, depending on the extent of elaboration the individual engages in, high or low ([Briñol et al., 2007](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr6-00332941241291497)). Finally, it is important to mention that the persuasive efficacy through the transit of the central route in the processing of persuasion is more enduring than via the peripheral route ([Petty and Cacioppo (1986)](https://journals.sagepub.com/doi/full/10.1177/00332941241291497?casa_token=6BiQc7wN70EAAAAA%3AFDWpbOADMuj8vbTSVRlygW9nf8F2g8_V4zJKJsQai7FH_QtNPWfalIPT6qywyBmxWhFHfaEFH-csyw#bibr51-00332941241291497).

==Maybe also a small pre-testing: "You did not follow the advice, could you please tell us why?"== I think we have tried that. The problem is that the decision making process is complicated so it is not always obvious to pick up the cues by ourselves.

We want to 'replicate' the general mechanism: peripheral and central
What do they mean?
Peripheral: emotional, trust (benevolence, integrity)
Central: Higher quality of information, expertise (competence)

### Manipulation 2

Another manipulation: 
simply remove the one without using, so remove the "No" in the AI use
Mix 1 and Mix 2
By doing so, we are able to understand the role of "consistency"
Direct implication: do not disclose the one that you did not use



==Remember to exclude the None group if we ask the generative AI disclosure problems==

### For mechanism 2:

I would like to directly measure the perceived credibility of the disclosure. Comparing to the previous mechanism, where I ask the question about 'report credibility,' now I directly ask their perceived credibility on the disclosure.

We should measure this:
>The  impact of human involvement through this route can vary; it may either enhance or diminish consumers’  adherence to the advice, depending on their perceptions of the human’s contribution to the overall quality of  the advice (Petty and Cacioppo, 1986). The literature offers evidence supporting both potential outcomes.

**Instructions for Participants:** The following statements are about the 'Generative AI Disclosure' you saw. Please tell us your impression of the disclosure itself.

**Response Scale:** 7-point scale (1 = Strongly Disagree, 7 = Strongly Agree)

**Proposed Items (7-point Likert scale: 1 = Strongly Disagree, 7 = Strongly Agree):**

1. The disclosure is believable. (Adapted from Appelman & Sundar, 2015 )  
    
2. The claims made in the disclosure are accurate. (Adapted from the PERCRED Scale )  
    
3. I am confident that the statements in the disclosure are true. (Adapted from the PERCRED Scale )  
    
4. The disclosure is trustworthy. (Adapted from Meyer, 1988 ; Ohanian, 1990 )  
    
5. The disclosure seems honest. (Adapted from Reysen Honesty Scale ; Ohanian, 1990 )  
    
6. The disclosure reflects the genuine intentions of the company. (Adapted from the PERCRED Scale )

Mechanism 1 is that the disclosure with "No" would elicit the 

"Imagine you need to make a significant investment decision. You have access to advice from a top-performing human financial analyst and a top-performing AI forecasting system. Assuming both have a strong track record, which source of advice would you choose to follow?" (Options: The human analyst, The AI system, and Human-AI system).

### Three mechanisms?
1. **Evaluative Frame Shift**: Prime effect of the disclosure
	1. The explicit disclosure of production process break the epistemic authority of the report, causing the distrust and skepticism
2. **Source Skepticism**: Perceived validity of disclosure (to explain the diffs across conditions)
3. **Perceived Competence**: Fundamental feelings towards AI and AI-human collaboration

It should be the case that the None group has lower Evaluative Frame Shift measures.
All of the disclosure groups should have Frame Shift
Then, the difference among the groups are determined by the Mechanism 2 and 3

Yesterday, Jingyi raised the question that the Mechanism 2 and 3 may be correlated: only the people who believe deep AI-assisted report is better will suspect the under-report of AI.
As a result, it could be putting the key into the 'source skepticism', which is determined by what attitude you have towards the AI-assisted report.

- [ ]  ==Mechanism 3, should we measure the expertise of analyst or organization?==
- [ ] ==How to think about the heterogeneity of participants?==

Group 1: don't believe AI will do much of the work
Group 2: thinks AI is good

Radical transparency of YYY may be a good thing

Coherence in Perceived Competence: 



# Frame Shift
- While making your decision, to what extent were you focused on...?"
	- - "...the financial health of the company." (1 = Not at all, 7 = Very Much)
	- "...the process used to create the report." (1 = Not at all, 7 = Very Much)


- "Please rate how important each of the following factors was in your final investment decision." (Slider: 0 = _Not at all important_ to 100 = _Extremely important_)
    
    - The company's financial performance
    - The overall market trends
    - **The methodology used to generate the report**
    - The expertise of the analyst

- “I made the investment decision without any influence of report”
- Or a slide bar of how much did they influence by the Report Recommendation (Left: self analysis; Right: following the recommendation.) We can also specify: 100 means that you made the investment decision because the you trust the report; 0 means that you did not trust the report and made your own decision
- Solipsistic Introjection?
- 
# Disclosure Skeptism
"In the report, the author disclosed the use of Generative AI in the report, to what extent do you think it reflects the actual use in the report?"
- Or, "to what extent do you think the author reports truthfully about the actual use of AI?"

"I believe the Generative AI use disclosure is based on facts/.."
"I concern that the Generative AI disclosure is not reported truthfully." (R)
"I believe the analyst is honest in the Generative AI disclosure."

From Bodoff and Hirsch (2023)
>We measure disclosure credibility by directly asking the experiment participants
questions based on Meyer’s (1988) credibility model. Meyer suggests a credibility scale model which is based on two factors: believability and community concern. The community concern is relevant to Meyer’s study since it is focused on newspaper credibility which involves the community’s interest or affiliation. We use only the believability factor and two other items that are relevant to our setting: (1) tells the whole story, (2) believable and (3) trustworthy. The terms were (1)“The information provided in the management comment does not tell the whole story” (reverse coding), (2)“The information provided in the management comment is believable” and (3):“The information provided in the management comment is trustworthy”. Each item was measured using a five-level Likert scale.

From Ford et al. (1990, JCR)
"The report includes a disclaimer of the Generative AI use in preparing the report. How likely is it the disclosure is true?"
>Two nine-point skepticism measures were developed: (1) "How likely is it that this claim is true?" anchored by "not at all likely" and "extremely likely," and (2) “How skeptical are you about the truth of this claim?" anchored by "not at all skeptical" and "extremely skeptical.



==Not too many things happen in here, just capture the truthfulness and that's it. ==

# Perceived traits of analyst and firm
### **Trustworthiness and Expertise**

Source credibility in Behm-Morawitz et al. (2025)
>Source Credibility  Source credibility was measured based on Lombardi et al.’s (2014) and McCroskey and Teven’s (1999) measures of source characteristics related to trustworthiness and expertise. Participants were asked to rate the source they used (ChatGPT, Google, or AP News) on five characteristics: fair, accurate, credible, trustworthy, and believable.

Trustworthiness
>Kirkpatrick and Locke’s (1996)
>The items asked participants to rate their agreement with the following statements: (1) I have complete trust in the author, (2) I find it difficult to trust the author (we reverse coded this item), (3) I do not believe what the author says (reverse coded), and (4) The author was trustworthy. The dependent measure of perceptions of author trustworthiness reflected average certainty ratings across the four items.

Questions about perceived firm reputation and status

### **Competence** (Ability & Expertise)

- I feel confident in this analyst's abilities.
    
- The analyst is skilled in financial analysis.
    
- The analyst has the expertise needed to make good investment recommendations.
    

### **Benevolence** (Care & Good Intentions)

- The analyst seems to have my best interests at heart.
    
- The analyst likely cares about the welfare of investors like me.
    
- I believe the analyst genuinely wants to help me make a good investment decision.
    

### **Integrity** (Honesty & Principles)

- The analyst seems honest.
    
- The analyst appears to have a strong sense of moral principles.
    
- I believe the analyst would be truthful in their communications.

### **Competence - Firm** (Capability & Effectiveness)

- This firm is highly competent in the investment industry.
- The firm has the resources and expertise to provide high-quality investment advice.
- I am confident in this firm's ability to perform its job well.
    

### **Benevolence - Firm** (Client-Focus & Good Will)

- This firm puts its clients' interests ahead of its own.
- This firm seems to genuinely care about its clients' financial success.
- Helping clients is a top priority at this firm.

### **Integrity - Firm** (Ethics & Fairness)

- This firm operates with a high degree of integrity.
- The firm adheres to sound ethical principles.
- I believe this firm is honest in its dealings with clients.
 
 ==Maybe worth randomizing the order of three traits==

### It would have been better with AI
Yanuo reminds me of a possible scenario where people doesn't necessarily love AI. The under-use of AI just serve as a possibility that "the report might get better if the AI is involved."

Maybe just directly ask "Do you think (a different use) of AI will improve the quality of the report?"
"Or, if there is another use of AI, will you change your answer?" 

One potential mechanism:
- people exert less effort in analyzing the report when they see all AI labels
Is the lowered following rate a sign of "distrust" or "discretion"?

"Verdian Equity Research is working on improving the quality of their investment report, do you think there is a better way to incorporate the AI use in their investment report preparation?"



### Memo
- Adjust the bonus to 2 extra 200 pounds instead of 3 ==DONE==
- What should we put into the "None" group for the disclaimer questions? ==NO==
	- "The report has Generative AI involvement. Now please answer questions..."
	- It could be interesting as a 'artificial shock' to test the Mechanism 1 -- we put back the cue and see if we can do the same frame shift
	- But the scenario is different -- use in caution
- Add questions ==DONE==
- Randomize the questions in Qualtrics ==DONE==

