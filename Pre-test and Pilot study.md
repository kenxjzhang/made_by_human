# Things we are going to test in the pre-testing
### Are the reports valid?
We don't want to see everyone is choosing the recommended companies, nor we want to see them deflect all the time.
Questions to ask about what they think about the report?
### Are the compensations reasonable?
How long does it take to finish the report? Do people complain about the low compensation or not finish the report reading?
### Are the questions valid?
What do people think about the mechanism questions?

### Do participants notice the AI disclosure?
Two scenario: 1) people did not notice, and 2) people generally think AI is irrelevant in the report

For 1), we can improve the visibility by re-arranging the position and highlighting the AI disclosure section 
For 2), it becomes interesting: is ignoring the AI disclaimer in making decision a story to tell?

On the other hand, it may not be a bad decision to directly reframe the study into AI disclosure. It can still be a study about 'financial decision', but in the introduction we explicitly tell them the company is experimenting the AI disclosure with its analysts.

The decision will based on the reaction of the question:
>Thinking back to your investment decision, to what extent did the 'Generative AI Disclosure' section of the report influence your choice? Please select the option that best describes your experience.
>- Yes, it made me <strong>more</strong> confident in and more likely to follow the report&#39;s recommendation.
>- Yes, it made me <strong>less</strong> confident in and less likely to follow the report&#39;s recommendation.
>- I noticed the disclosure, but it <strong>did not influence</strong> my final decision one way or the other.
>- <strong>I do not recall</strong> seeing or considering the &#39;Generative AI Disclosure&#39; section when making my decision.

### No need to collect demographic in the pre-testing
I plan to not include the demographic questions in the pre-testing.


### Questions prepared
From [[Andras meeting on 20250715]]:
- [ ] Pretesting:
	- [ ] "What do you think the study is about?" to understand if the participants guess the intention of the study
	- [ ] "To what extent do you think the report is realistic?" to solve the concerns around the analysis report
	- [ ] "Based on your impression, does the Information/Analysis/Recommendation section involve Generative AI use?" to know if they notice and remember the AI use section
	- [ ] "Any other comments for the report or study?"

Include them in the Qualtrics(YES)

# Pre-testing Questions
Random 1/2 of participants:
1. In your own words, what do you believe was the main research question or purpose of this study?
2. Did you have any specific guesses about the hypothesis the researchers were trying to test? If so, what were they?
3. On a scale from 1 to 7, how realistic did the investment report feel to you?
4. Could you briefly explain your rating? What, if anything, made the report feel particularly realistic or unrealistic?

Random 1/2 of participants:
1. Was Generative AI used in **gathering information** for the report?
2. Was Generative AI used in **conducting the analysis** for the report?
3. Was Generative AI used in **formulating the recommendation** for the report?
4. Thinking back to your investment decision, to what extent did the 'Generative AI Disclosure' section of the report influence your choice? Please select the option that best describes your experience.



# Pre-testing reports
**Title:**
Evaluate Professional Reports (~10 minutes)

Descriptions:
Hello! We are researchers studying how people perceive professionally written documents.

In this study, you will be asked to:

1. Carefully read two short investment reports (each is approx. 700 words).
    
2. Answer a few questions about your impressions after reading each report.
    

The study requires careful reading, so please ensure you are in a quiet environment where you can focus.

A desktop or laptop is strongly recommended for this task.

Your responses are completely anonymous. Thank you for your contribution to our research!


# Pre-testing for reports
### Pre-testing
In the pre-testing, we want to make sure that our reports are not totally obvious that they are definitely AI-generated, because that would make our disclaimer in the study less credible. We don't want our participants to hold a strong belief that the report is definitely AI generated when our AI disclosure says the whole report does not involve AI. As a result, we want to see a variance among people who think the report is by human or AI, or people who can not tell the source of the report.

In the pre-testing, we recruited 100 participants to read one of the four prepared reports. After reading the report, they were asked the questions about how realistic the report is. 

Question 1: "Based on your own impression of the reports, how likely is it that the text you just read was AI-generated (rather than human-written)?" 
Question 2: “What aspects of the text influenced your rating? Please share your perspectives.”

>By the way, when we run pre-tests of manipulation (as a kind of pre-experimental manipulation check), usually, we hope to find a significant difference (e.g., if I want to signal that one applicant is from a higher social class background than the other, then I'd want to see that participants taking the pretest perceive that candidate to be significantly higher on the relevant variables). But in cases like this one, I think you basically just want to rule out anything that would be really disruptive for the experiment. So, for example, if you find that, on average, people can't really tell with a lot of certainty whether a report was AI or human-authored (or at least you don't find evidence suggesting that they do), that would be a helpful thing, because it would mean that your actual manipulations (your labels) won't be seen as obvious lies by most respondents. So, in that sense, not getting a clear signal and having some evidence consistent with ambiguity would be a helpful feature in this case. Does that make sense?


The results show that people are not systematically think the reports are written by AI or written by human. 
[[asset/d0fa888a17b751d0bf89f81de6606c52_MD5.jpeg|Open: Code_Generated_Image.png]]
![[asset/d0fa888a17b751d0bf89f81de6606c52_MD5.jpeg]]
Contradictory Reasoning: The same characteristics (e.g., being "well-structured," "fact-based," or "neutral") were often cited as evidence for a report being both AI-generated and human-written. This suggests that people's ideas about what constitutes AI or human writing are not consistent.

Preconceived Notions: Participants' judgments seem to be heavily influenced by their preconceived notions of what AI-writing should sound like (e.g., robotic, impersonal, overly formal).

Difficulty in Detection: The fact that a significant number of people were incorrect in their assessments, especially for the human-written reports, highlights the increasing difficulty in distinguishing between high-quality AI-generated text and human writing.

The difficulty in detection is not surprising. Previous studies show that even earlier versions of generative AI tools are hard to detect. (Waltzer et al, 2023; Gunser et al, 2021)

# Pilot study 
The main idea of pilot study is: 
1) testing the validity of the study
2) see if people can guess the study purpose. 
We recruited 40 participants in the pilot study. 
For 1), we want to see there is a variance in choosing the reports. We don't want to see that people always choose one of the three companies in the report. For whatever reasons, if people are choosing the same company all the time, we are not able to find the meaningful variance in how AI labels would change their decision making. In our pilot study, we implemented the same survey flow as in the main study—consent, introduction, materials, and main Investment decisions—to test whether the people make different choices in the company. 
Our results show that people did not blindly followed the report recommendation or any other particular company.
> - Celestial Optics (CELO): 11 (Highest returned)
> - Vista Therapeutics (VSTA): 6 (Recommended)
> - Adaptive Vision (ADPT): 5
> 
> - Hamilton Sterling Group (HSG): 9
> - Kinetic Workforce (KNTC): 8 (Recommended and highest returned)
> - Apollo Medical (APLO): 2

In 2), we also did not find evidence that people systematically make correct guess about our study purpose and hypothesis. 5/20 people guessed it correctly about our study purpose, but only 3 of them guessed the hypothesis. 7/20 people mentioned "AI" but are not on points to our study purpose. Noted that even when people guessed the hypothesis, the demand effects are much less than we anticipated according to recent study (reference needed).

We made decision about delaying the dates after the launch dates. It may serve the function that less suspicious from participants about we always picking the right/wrong companies. In a sense that we as researchers also don't know which company is the best.
- In the pilot study, we set the period of March 18 to August 18.
- In the main study, we set the period of March 30 to August 30.

Overall, the pilot study shows that the reports are informative and people use it to make their investment decisions.